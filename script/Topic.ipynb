{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T03:41:50.816833Z",
     "start_time": "2021-03-28T03:41:42.012211Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordninja==2.0.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (2.0.0)\n",
      "Requirement already satisfied: scikit-learn==0.22.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (0.22.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.22.2) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.22.2) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.22.2) (1.5.2)\n",
      "Requirement already satisfied: lime==0.2.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (0.2.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (4.50.2)\n",
      "Requirement already satisfied: numpy in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (3.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (0.22.2)\n",
      "Requirement already satisfied: scipy in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (1.5.2)\n",
      "Requirement already satisfied: pillow==5.4.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (5.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from lime==0.2.0) (0.17.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lime==0.2.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lime==0.2.0) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lime==0.2.0) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lime==0.2.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lime==0.2.0) (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18->lime==0.2.0) (0.17.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-image>=0.12->lime==0.2.0) (2.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-image>=0.12->lime==0.2.0) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-image>=0.12->lime==0.2.0) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from scikit-image>=0.12->lime==0.2.0) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib->lime==0.2.0) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit-image>=0.12->lime==0.2.0) (4.4.2)\n",
      "Requirement already satisfied: tensorflow in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.15.6)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/zhuzeyu/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wordninja==2.0.0             # for splitting joined words\n",
    "!pip3 install scikit-learn==0.22.2         # for one-hot encoding\n",
    "!pip3 install lime==0.2.0                  # for explaining model predictions\n",
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T03:41:50.839575Z",
     "start_time": "2021-03-28T03:41:50.822154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-64-71c57fbc687f>:8: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is GPU available:  False\n",
      "GPU(s) found: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import tensorflow as tf\n",
    "# Check if any GPU is detected\n",
    "print(\"Is GPU available: \", tf.test.is_gpu_available())\n",
    "print(\"GPU(s) found: \")\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:35:03.949995Z",
     "start_time": "2021-03-27T15:35:03.506973Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = os.getcwd().replace('script', 'data')\n",
    "data = pd.read_csv(data_path + '/labelled_newscatcher_dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:35:04.521570Z",
     "start_time": "2021-03-27T15:35:04.505631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108769</th>\n",
       "      <td>NATION</td>\n",
       "      <td>https://www.vanguardngr.com/2020/08/pdp-govern...</td>\n",
       "      <td>vanguardngr.com</td>\n",
       "      <td>2020-08-08 02:40:00</td>\n",
       "      <td>PDP governors’ forum urges security agencies t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108770</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>https://www.patentlyapple.com/patently-apple/2...</td>\n",
       "      <td>patentlyapple.com</td>\n",
       "      <td>2020-08-08 01:27:12</td>\n",
       "      <td>In Q2-20, Apple Dominated the Premium Smartpho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108771</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.belfastlive.co.uk/news/health/coro...</td>\n",
       "      <td>belfastlive.co.uk</td>\n",
       "      <td>2020-08-12 17:01:00</td>\n",
       "      <td>Coronavirus Northern Ireland: Full breakdown s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108772</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>https://www.thenews.com.pk/latest/696364-paul-...</td>\n",
       "      <td>thenews.com.pk</td>\n",
       "      <td>2020-08-05 04:59:00</td>\n",
       "      <td>Paul McCartney details post-Beatles distress a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108773</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>https://www.balls.ie/football/shane-duffy-brig...</td>\n",
       "      <td>balls.ie</td>\n",
       "      <td>2020-08-09 10:25:26</td>\n",
       "      <td>Report: Talks Underway To Keep Shane Duffy In ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108774 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                topic                                               link  \\\n",
       "0             SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...   \n",
       "1             SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...   \n",
       "2             SCIENCE  https://www.express.co.uk/news/science/1322607...   \n",
       "3             SCIENCE  https://www.ndtv.com/world-news/glaciers-could...   \n",
       "4             SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...   \n",
       "...               ...                                                ...   \n",
       "108769         NATION  https://www.vanguardngr.com/2020/08/pdp-govern...   \n",
       "108770       BUSINESS  https://www.patentlyapple.com/patently-apple/2...   \n",
       "108771         HEALTH  https://www.belfastlive.co.uk/news/health/coro...   \n",
       "108772  ENTERTAINMENT  https://www.thenews.com.pk/latest/696364-paul-...   \n",
       "108773         SPORTS  https://www.balls.ie/football/shane-duffy-brig...   \n",
       "\n",
       "                   domain       published_date  \\\n",
       "0          eurekalert.org  2020-08-06 13:59:45   \n",
       "1                pulse.ng  2020-08-12 15:14:19   \n",
       "2           express.co.uk  2020-08-13 21:01:00   \n",
       "3                ndtv.com  2020-08-03 22:18:26   \n",
       "4               thesun.ie  2020-08-12 19:54:36   \n",
       "...                   ...                  ...   \n",
       "108769    vanguardngr.com  2020-08-08 02:40:00   \n",
       "108770  patentlyapple.com  2020-08-08 01:27:12   \n",
       "108771  belfastlive.co.uk  2020-08-12 17:01:00   \n",
       "108772     thenews.com.pk  2020-08-05 04:59:00   \n",
       "108773           balls.ie  2020-08-09 10:25:26   \n",
       "\n",
       "                                                    title lang  \n",
       "0       A closer look at water-splitting's solar fuel ...   en  \n",
       "1       An irresistible scent makes locusts swarm, stu...   en  \n",
       "2       Artificial intelligence warning: AI will know ...   en  \n",
       "3        Glaciers Could Have Sculpted Mars Valleys: Study   en  \n",
       "4       Perseid meteor shower 2020: What time and how ...   en  \n",
       "...                                                   ...  ...  \n",
       "108769  PDP governors’ forum urges security agencies t...   en  \n",
       "108770  In Q2-20, Apple Dominated the Premium Smartpho...   en  \n",
       "108771  Coronavirus Northern Ireland: Full breakdown s...   en  \n",
       "108772  Paul McCartney details post-Beatles distress a...   en  \n",
       "108773  Report: Talks Underway To Keep Shane Duffy In ...   en  \n",
       "\n",
       "[108774 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:35:05.533332Z",
     "start_time": "2021-03-27T15:35:05.509830Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEALTH           15000\n",
       "WORLD            15000\n",
       "NATION           15000\n",
       "ENTERTAINMENT    15000\n",
       "SPORTS           15000\n",
       "BUSINESS         15000\n",
       "TECHNOLOGY       15000\n",
       "SCIENCE           3774\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic Science is with much fewer records, may need to make this up with some other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:35:16.088307Z",
     "start_time": "2021-03-27T15:35:15.927412Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickles\n",
    "# data.to_pickle(data_path + \"/original_data.pkl\")\n",
    "# data = pd.read_pickle(data_path + \"/original_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T03:20:17.061264Z",
     "start_time": "2021-03-28T03:20:17.053102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhuzeyu/Desktop/COMP3359/Project/COMP__3359__GROUP8/data/glove.6B.50d.txt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_path = data_path + '/glove.6B.50d.txt'\n",
    "glove_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T03:24:01.081056Z",
     "start_time": "2021-03-28T03:24:01.036945Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# COMP3359 Artificial Intelligence Applications                                #\n",
    "# Department of Computer Science, HKU                                          #\n",
    "# Module 4 - Example: Classification of Text                                   #\n",
    "# Utility functions for loading GloVe word embeddings                          #\n",
    "#                                                                              #\n",
    "# Reference: uillaume-chevalier/GloVe-as-a-TensorFlow-Embedding-Layer          #\n",
    "# https://github.com/guillaume-chevalier/GloVe-as-a-TensorFlow-Embedding-Layer #\n",
    "################################################################################\n",
    "\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def load_embedding_from_disks(glove_filename, with_indexes=True):\n",
    "    \"\"\"\n",
    "    Read a GloVe txt file. If `with_indexes=True`, we return a tuple of two dictionnaries\n",
    "    `(word_to_index_dict, index_to_embedding_array)`, otherwise we return only a direct \n",
    "    `word_to_embedding_dict` dictionnary mapping from a string to a numpy array.\n",
    "    \"\"\"\n",
    "    if with_indexes:\n",
    "        word_to_index_dict = dict()\n",
    "        index_to_embedding_array = []\n",
    "    else:\n",
    "        word_to_embedding_dict = dict()\n",
    "\n",
    "    \n",
    "    with open(glove_filename, 'r') as glove_file:\n",
    "        for (i, line) in enumerate(glove_file):\n",
    "            \n",
    "            split = line.split(' ')\n",
    "            \n",
    "            word = split[0]\n",
    "            \n",
    "            representation = split[1:]\n",
    "            representation = np.array(\n",
    "                [float(val) for val in representation]\n",
    "            )\n",
    "            \n",
    "            if with_indexes:\n",
    "                word_to_index_dict[word] = i\n",
    "                index_to_embedding_array.append(representation)\n",
    "            else:\n",
    "                word_to_embedding_dict[word] = representation\n",
    "\n",
    "    _WORD_NOT_FOUND = [0.0]* len(representation)  # Empty representation for unknown words.\n",
    "    if with_indexes:\n",
    "        _LAST_INDEX = i + 1\n",
    "        word_to_index_dict = defaultdict(lambda: _LAST_INDEX, word_to_index_dict)\n",
    "        index_to_embedding_array = np.array(index_to_embedding_array + [_WORD_NOT_FOUND])\n",
    "        return word_to_index_dict, index_to_embedding_array\n",
    "    else:\n",
    "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
    "        return word_to_embedding_dict\n",
    "\n",
    "\n",
    "def sentence_to_word_ids(sentence, word_to_index):\n",
    "    \"\"\"\n",
    "    Note: there might be a better way to split sentences for GloVe.\n",
    "    Please look at the documentation or open an issue to suggest a fix.\n",
    "    \"\"\"\n",
    "    # Separating punctuation from words:\n",
    "    for punctuation_character in punctuation:\n",
    "        sentence = sentence.replace(punctuation_character, \" {} \".format(punctuation_character))\n",
    "    # Removing double spaces and lowercasing:\n",
    "    sentence = sentence.replace(\"  \", \" \").replace(\"  \", \" \").lower().strip()\n",
    "    # Splitting on every space:\n",
    "    split_sentence = sentence.split(\" \")\n",
    "    # Converting to IDs:\n",
    "    ids = [word_to_index[w.strip()] for w in split_sentence]\n",
    "    return ids, split_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T04:43:54.328579Z",
     "start_time": "2021-03-28T04:43:47.603301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400002, 50)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index_dict, index_to_embedding_array = load_embedding_from_disks(glove_path, with_indexes=True)\n",
    "index_to_embedding_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T04:14:12.549353Z",
     "start_time": "2021-03-28T04:14:12.468250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train dev split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "X = data['title'].to_numpy()\n",
    "y_beforelabel = data['topic'].to_numpy()\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "y = le_y.fit_transform(y_beforelabel).reshape(-1, 1)\n",
    "X_train, X_traindev, y_train, y_traindev = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T04:14:21.542519Z",
     "start_time": "2021-03-28T04:14:19.088842Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_token = [ sentence_to_word_ids(x, word_to_index_dict)[0] for x in X_train ]\n",
    "X_traindev_token = [ sentence_to_word_ids(x, word_to_index_dict)[0] for x in X_traindev ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T04:33:15.774794Z",
     "start_time": "2021-03-28T04:33:15.702917Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Construct our tf.data.Dataset Pipeline to Load Data \"\"\"\n",
    "# tf.data.Dataset pipeline is used to load our data and feed to model for training\n",
    "# with higher efficiency.\n",
    "# For more instructions on tf.data.Dataset pipelines, see:\n",
    "#    https://www.tensorflow.org/guide/data\n",
    "#    https://www.tensorflow.org/guide/data_performance\n",
    "\n",
    "# Training dataset pipeline\n",
    "train_ds_glove = tf.data.Dataset.from_generator( lambda: zip(X_train_token, y_train), output_types=(tf.int32,tf.int32))\n",
    "train_ds_glove = train_ds_glove.shuffle(buffer_size=20000)\n",
    "train_ds_glove = train_ds_glove.padded_batch(batch_size=500, padded_shapes=([None], [1]))\n",
    "# Test dataset pipeline\n",
    "traindev_ds_glove = tf.data.Dataset.from_generator( lambda: zip(X_traindev_token, y_traindev), output_types=(tf.int32,tf.int32))\n",
    "traindev_ds_glove = traindev_ds_glove.padded_batch(batch_size=500, padded_shapes=([None], [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T05:01:46.952545Z",
     "start_time": "2021-03-28T04:57:05.605776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  400002\n",
      "Embedding Dim:  50\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 50)          20000100  \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 20,000,151\n",
      "Trainable params: 51\n",
      "Non-trainable params: 20,000,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "175/175 [==============================] - 9s 44ms/step - loss: -17.8713 - accuracy: 0.1374 - val_loss: -66.2283 - val_accuracy: 0.1367\n",
      "Epoch 2/30\n",
      "175/175 [==============================] - 10s 44ms/step - loss: -81.5869 - accuracy: 0.1387 - val_loss: -130.5866 - val_accuracy: 0.1367\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 9s 41ms/step - loss: -144.5981 - accuracy: 0.1382 - val_loss: -195.0233 - val_accuracy: 0.1367\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 10s 47ms/step - loss: -207.7534 - accuracy: 0.1379 - val_loss: -259.5261 - val_accuracy: 0.1367\n",
      "Epoch 5/30\n",
      "175/175 [==============================] - 12s 52ms/step - loss: -272.6011 - accuracy: 0.1381 - val_loss: -324.0762 - val_accuracy: 0.1367\n",
      "Epoch 6/30\n",
      "175/175 [==============================] - 9s 39ms/step - loss: -336.0995 - accuracy: 0.1370 - val_loss: -388.7559 - val_accuracy: 0.1367\n",
      "Epoch 7/30\n",
      "175/175 [==============================] - 8s 39ms/step - loss: -399.0764 - accuracy: 0.1389 - val_loss: -453.2194 - val_accuracy: 0.1367\n",
      "Epoch 8/30\n",
      "175/175 [==============================] - 12s 62ms/step - loss: -464.5986 - accuracy: 0.1380 - val_loss: -517.9184 - val_accuracy: 0.1367\n",
      "Epoch 9/30\n",
      "175/175 [==============================] - 9s 43ms/step - loss: -526.7700 - accuracy: 0.1378 - val_loss: -582.6074 - val_accuracy: 0.1367\n",
      "Epoch 10/30\n",
      "175/175 [==============================] - 9s 41ms/step - loss: -594.4114 - accuracy: 0.1374 - val_loss: -647.1069 - val_accuracy: 0.1367\n",
      "Epoch 11/30\n",
      "175/175 [==============================] - 12s 54ms/step - loss: -657.0223 - accuracy: 0.1389 - val_loss: -711.6924 - val_accuracy: 0.1367\n",
      "Epoch 12/30\n",
      "175/175 [==============================] - 9s 39ms/step - loss: -721.7736 - accuracy: 0.1383 - val_loss: -776.3838 - val_accuracy: 0.1367\n",
      "Epoch 13/30\n",
      "175/175 [==============================] - 9s 39ms/step - loss: -778.5460 - accuracy: 0.1400 - val_loss: -840.7868 - val_accuracy: 0.1367\n",
      "Epoch 14/30\n",
      "175/175 [==============================] - 9s 41ms/step - loss: -851.0802 - accuracy: 0.1375 - val_loss: -905.4624 - val_accuracy: 0.1367\n",
      "Epoch 15/30\n",
      "175/175 [==============================] - 8s 38ms/step - loss: -910.3386 - accuracy: 0.1387 - val_loss: -970.1038 - val_accuracy: 0.1367\n",
      "Epoch 16/30\n",
      "175/175 [==============================] - 10s 48ms/step - loss: -978.6928 - accuracy: 0.1376 - val_loss: -1034.7196 - val_accuracy: 0.1367\n",
      "Epoch 17/30\n",
      "175/175 [==============================] - 9s 43ms/step - loss: -1036.6071 - accuracy: 0.1377 - val_loss: -1099.2482 - val_accuracy: 0.1367\n",
      "Epoch 18/30\n",
      "175/175 [==============================] - 10s 46ms/step - loss: -1098.1744 - accuracy: 0.1388 - val_loss: -1163.9680 - val_accuracy: 0.1367\n",
      "Epoch 19/30\n",
      "175/175 [==============================] - 8s 40ms/step - loss: -1160.3229 - accuracy: 0.1379 - val_loss: -1228.6296 - val_accuracy: 0.1367\n",
      "Epoch 20/30\n",
      "175/175 [==============================] - 9s 44ms/step - loss: -1225.0569 - accuracy: 0.1377 - val_loss: -1293.2126 - val_accuracy: 0.1367\n",
      "Epoch 21/30\n",
      "175/175 [==============================] - 8s 39ms/step - loss: -1285.4879 - accuracy: 0.1395 - val_loss: -1357.8589 - val_accuracy: 0.1367\n",
      "Epoch 22/30\n",
      "175/175 [==============================] - 8s 38ms/step - loss: -1354.3384 - accuracy: 0.1386 - val_loss: -1422.3939 - val_accuracy: 0.1367\n",
      "Epoch 23/30\n",
      "175/175 [==============================] - 8s 40ms/step - loss: -1423.6824 - accuracy: 0.1383 - val_loss: -1487.0020 - val_accuracy: 0.1367\n",
      "Epoch 24/30\n",
      "175/175 [==============================] - 9s 40ms/step - loss: -1484.6093 - accuracy: 0.1378 - val_loss: -1551.4730 - val_accuracy: 0.1367\n",
      "Epoch 25/30\n",
      "175/175 [==============================] - 9s 40ms/step - loss: -1557.3761 - accuracy: 0.1387 - val_loss: -1616.1113 - val_accuracy: 0.1367\n",
      "Epoch 26/30\n",
      "175/175 [==============================] - 8s 40ms/step - loss: -1608.6011 - accuracy: 0.1390 - val_loss: -1680.9139 - val_accuracy: 0.1367\n",
      "Epoch 27/30\n",
      "175/175 [==============================] - 12s 52ms/step - loss: -1669.2878 - accuracy: 0.1382 - val_loss: -1745.3712 - val_accuracy: 0.1367\n",
      "Epoch 28/30\n",
      "175/175 [==============================] - 10s 46ms/step - loss: -1740.8950 - accuracy: 0.1390 - val_loss: -1809.9672 - val_accuracy: 0.1367\n",
      "Epoch 29/30\n",
      "175/175 [==============================] - 10s 46ms/step - loss: -1801.7683 - accuracy: 0.1385 - val_loss: -1874.4767 - val_accuracy: 0.1367\n",
      "Epoch 30/30\n",
      "175/175 [==============================] - 9s 44ms/step - loss: -1854.5520 - accuracy: 0.1380 - val_loss: -1938.9514 - val_accuracy: 0.1367\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Constructing Model with Pre-Trained Word Embedding \"\"\"\n",
    "\n",
    "# Get description of word embedding\n",
    "vocab_size, embedding_dim = index_to_embedding_array.shape\n",
    "print(\"Vocab Size: \", vocab_size)\n",
    "print(\"Embedding Dim: \", embedding_dim)\n",
    "\n",
    "# Construct embedding layer and use embedding vectors to set weights.\n",
    "# Set trainable=False to freeze the weights to prevent weight to be \n",
    "# changed during training.\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                            output_dim=embedding_dim,\n",
    "                                            weights=[index_to_embedding_array],\n",
    "                                            trainable=False)\n",
    "\n",
    "# Construct model using the pre-trained embedding layer.\n",
    "# This model learns by changing network weights in Dense layer.\n",
    "# (no trainable weights in GlobalAveragePooling layer)\n",
    "model_glove = tf.keras.Sequential([\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "print(model_glove.summary())\n",
    "\n",
    "# Compile model\n",
    "model_glove.compile(loss='binary_crossentropy',\n",
    "                    optimizer=tf.keras.optimizers.Adam(1e-2),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model_glove.fit(train_ds_glove, epochs=30,\n",
    "                          validation_data=traindev_ds_glove, \n",
    "                          validation_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is not converged at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T05:02:13.786611Z",
     "start_time": "2021-03-28T05:02:13.663701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      " New evidence raised in stepmum's third trial in Melbourne for alleged incest \n",
      "\n",
      "Corresponding ids: \n",
      " [50, 906, 1073, 6, 400001, 57, 1534, 245, 801, 6, 4179, 10, 1549, 25944] \n",
      "\n",
      "Corresponding type: \n",
      " ['ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT'\n",
      " 'ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT'\n",
      " 'ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT' 'ENTERTAINMENT'\n",
      " 'ENTERTAINMENT' 'BUSINESS'] \n",
      "\n",
      "Final prediction: \n",
      " ['ENTERTAINMENT'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction example\n",
    "from scipy import stats\n",
    "example = X_train[0]\n",
    "print(\"Sentence: \\n\",\n",
    "      example, \"\\n\")\n",
    "ids = sentence_to_word_ids(example, word_to_index_dict)[0]\n",
    "print(\"Corresponding ids: \\n\",\n",
    "      sentence, \"\\n\")\n",
    "print(\"Corresponding type: \\n\",\n",
    "      le_y.inverse_transform(model_glove.predict(ids).flatten().astype(int)), \"\\n\")\n",
    "print(\"Final prediction: \\n\", \n",
    "      le_y.inverse_transform(stats.mode(model_glove.predict(ids).flatten().astype(int))[0]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
